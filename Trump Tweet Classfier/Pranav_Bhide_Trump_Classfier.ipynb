{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f0dad7-b1fa-48e2-80d8-f3114bc4f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c8f638c-6727-4265-8d20-69b43176bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16 = pd.read_csv(\"Trump_2016.csv\")\n",
    "df_18 = pd.read_csv(\"Trump_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92717b90-ebb6-4d56-9b54-6a96fad83788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3649</td>\n",
       "      <td>3649</td>\n",
       "      <td>3648</td>\n",
       "      <td>3648.000000</td>\n",
       "      <td>3648.000000</td>\n",
       "      <td>3648</td>\n",
       "      <td>3.648000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>3641</td>\n",
       "      <td>3603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>MAKE AMERICA GREAT AGAIN!</td>\n",
       "      <td>01/10/2016 21:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1950</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8234.224507</td>\n",
       "      <td>22661.954770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.441187e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10423.880893</td>\n",
       "      <td>27375.048677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.712391e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.830000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3501.250000</td>\n",
       "      <td>9328.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.090000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5956.500000</td>\n",
       "      <td>16499.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.460000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9991.750000</td>\n",
       "      <td>27048.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.790000e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344806.000000</td>\n",
       "      <td>633253.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.150000e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                       text        created_at  \\\n",
       "count                 3649                       3649              3648   \n",
       "unique                   9                       3641              3603   \n",
       "top     Twitter for iPhone  MAKE AMERICA GREAT AGAIN!  01/10/2016 21:06   \n",
       "freq                  1950                          9                 3   \n",
       "mean                   NaN                        NaN               NaN   \n",
       "std                    NaN                        NaN               NaN   \n",
       "min                    NaN                        NaN               NaN   \n",
       "25%                    NaN                        NaN               NaN   \n",
       "50%                    NaN                        NaN               NaN   \n",
       "75%                    NaN                        NaN               NaN   \n",
       "max                    NaN                        NaN               NaN   \n",
       "\n",
       "        retweet_count  favorite_count is_retweet        id_str  \n",
       "count     3648.000000     3648.000000       3648  3.648000e+03  \n",
       "unique            NaN             NaN          2           NaN  \n",
       "top               NaN             NaN      False           NaN  \n",
       "freq              NaN             NaN       3461           NaN  \n",
       "mean      8234.224507    22661.954770        NaN  7.441187e+17  \n",
       "std      10423.880893    27375.048677        NaN  3.712391e+16  \n",
       "min          0.000000        0.000000        NaN  6.830000e+17  \n",
       "25%       3501.250000     9328.500000        NaN  7.090000e+17  \n",
       "50%       5956.500000    16499.500000        NaN  7.460000e+17  \n",
       "75%       9991.750000    27048.500000        NaN  7.790000e+17  \n",
       "max     344806.000000   633253.000000        NaN  8.150000e+17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source             object\n",
       "text               object\n",
       "created_at         object\n",
       "retweet_count     float64\n",
       "favorite_count    float64\n",
       "is_retweet         object\n",
       "id_str            float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "created_at        1\n",
       "retweet_count     1\n",
       "favorite_count    1\n",
       "is_retweet        1\n",
       "id_str            1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_16.columns\n",
    "#df_16.head(10)\n",
    "display(df_16.describe(include='all'))\n",
    "display(df_16.dtypes)\n",
    "temp = df_16.isnull().sum()\n",
    "display(temp[temp > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dce9727e-846a-4916-bbfe-a5a773a59086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>Twitter Ads</td>\n",
       "      <td>This is a crossroads in the history of our civ...</td>\n",
       "      <td>10-13-2016 22:50:04</td>\n",
       "      <td>16977.0</td>\n",
       "      <td>33428.0</td>\n",
       "      <td>false</td>\n",
       "      <td>7.867006e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                               text  \\\n",
       "3023  Twitter Ads  This is a crossroads in the history of our civ...   \n",
       "\n",
       "               created_at  retweet_count  favorite_count is_retweet  \\\n",
       "3023  10-13-2016 22:50:04        16977.0         33428.0      false   \n",
       "\n",
       "            id_str  \n",
       "3023  7.867006e+17  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imputing the missing value\n",
    "#display(df_16[df_16['created_at'].isnull()==True]['text'])\n",
    "\n",
    "temp = df_16.loc[df_16['created_at'].isnull(), 'text'].values[0]\n",
    "temp = temp.split(',')\n",
    "\n",
    "df_16.loc[df_16['created_at'].isnull(), 'text'] = temp[0] \n",
    "df_16.loc[df_16['created_at'].isnull(), 'retweet_count'] = float(temp[2])  \n",
    "df_16.loc[df_16['created_at'].isnull(), 'favorite_count'] = float(temp[3]) \n",
    "df_16.loc[df_16['created_at'].isnull(), 'is_retweet'] = temp[4] \n",
    "df_16.loc[df_16['created_at'].isnull(), 'id_str'] = float(temp[5])\n",
    "df_16.loc[df_16['created_at'].isnull(), 'created_at'] = temp[1]\n",
    "df_16[df_16['created_at'] == temp[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3075d174-605f-4c39-88bc-6d16fe38714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check nulls again\n",
    "temp = df_16.isnull().sum()\n",
    "display(temp[temp > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d9aed680-ab50-4463-84cb-254f4a762080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class label 1 Android, 0 iPhone\n",
    "df_16['label'] = np.where(df_16['source'] == 'Twitter for Android', 1, 0)\n",
    "df_16_train = df_16[df_16['source'].isin(['Twitter for Android', 'Twitter for iPhone'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4d979517-9833-4dc5-a652-1716c3c0f638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17864\\2897490961.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_16_train['text'] = df_16_train['text'].apply(lambda x:str(x).lower())\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17864\\2897490961.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_16_train['text'] = df_16_train['text'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing \n",
    "df_16_train['text'] = df_16_train['text'].apply(lambda x:str(x).lower())\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    #text = re.sub(r'\\@\\w+|\\#', '', text)  # Remove @mentions and hashtags this is reducing accuracy so not removing\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "df_16_train['text'] = df_16_train['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9e0c642c-4ad1-44e6-9e65-999bfc770f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_16_train['text'], df_16_train['label'], test_size=0.2)\n",
    "\n",
    "#TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1bce831b-f06a-4ee0-9576-ca1933c3ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.824806</td>\n",
       "      <td>0.824443</td>\n",
       "      <td>0.824806</td>\n",
       "      <td>0.824381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.822916</td>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.822691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814359</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.774931</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.773453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.770543</td>\n",
       "      <td>0.780953</td>\n",
       "      <td>0.770543</td>\n",
       "      <td>0.763363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.755039</td>\n",
       "      <td>0.755254</td>\n",
       "      <td>0.755039</td>\n",
       "      <td>0.752137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision    Recall  F1-Score\n",
       "SVM                  0.824806   0.824443  0.824806  0.824381\n",
       "Random Forest        0.823256   0.822916  0.823256  0.822691\n",
       "Logistic Regression  0.813953   0.814359  0.813953  0.812576\n",
       "Decision Tree        0.775194   0.774931  0.775194  0.773453\n",
       "Gradient Boosting    0.770543   0.780953  0.770543  0.763363\n",
       "K-Nearest Neighbors  0.755039   0.755254  0.755039  0.752137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of classifiers to test\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"F1-Score\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "display(results_df.sort_values(by=\"Accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "596c6ff2-d511-48d6-afcd-9765cf2ec9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       362\n",
      "           1       0.82      0.74      0.78       283\n",
      "\n",
      "    accuracy                           0.81       645\n",
      "   macro avg       0.81      0.81      0.81       645\n",
      "weighted avg       0.81      0.81      0.81       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions and evaluate the classifier\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e3cb7cd-f144-4e75-8b9c-d4a349bd5050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       362\n",
      "           1       0.81      0.78      0.80       283\n",
      "\n",
      "    accuracy                           0.82       645\n",
      "   macro avg       0.82      0.82      0.82       645\n",
      "weighted avg       0.82      0.82      0.82       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC --This give better accuracy\n",
    "model = SVC()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions and evaluate the classifier\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dd267-a0f0-4ccf-8352-96490777d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameter tuning\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # Define a pipeline with TF-IDF Vectorizer and Logistic Regression\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer(stop_words='english', max_features=3000)),\n",
    "#     ('logreg', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define the hyperparameters grid to search\n",
    "# param_grid = {\n",
    "#     'logreg__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#     'logreg__solver': ['liblinear', 'saga'],  \n",
    "#     'tfidf__max_features': [1000, 3000, 5000] \n",
    "# }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Cross-Validation Accuracy:\", best_score)\n",
    "\n",
    "# # Evaluate on the test set\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Test Set Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3747d081-ba84-4d4f-bef7-5691ddf15f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17864\\1398221640.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_16_excluded['text'] = df_16_excluded['text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "df_16_excluded = df_16[~df_16['source'].isin(['Twitter for Android', 'Twitter for iPhone'])]\n",
    "df_16_excluded['text'] = df_16_excluded['text'].str.lower()\n",
    "\n",
    "#Vectorize\n",
    "X_exclude_tfidf = tfidf.transform(df_16_excluded['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c836000-7ff1-41e9-bb33-e502666d54ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 302, 1: 122})\n"
     ]
    }
   ],
   "source": [
    "# Prediction for non iphone and android tweets\n",
    "exclude_pred = model.predict(X_exclude_tfidf)\n",
    "from collections import Counter\n",
    "c = Counter(exclude_pred)\n",
    "print(c) \n",
    "#class label 1  (Trump), 0  (not trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498409c-a99a-4dc9-9528-a653a523d4ea",
   "metadata": {},
   "source": [
    "2018 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3bddb330-9107-4902-bf7c-0786e793843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the classifier to the 2018 data\n",
    "df_18['text'] = df_18['text'].str.lower()\n",
    "df_18['text'] = df_18['text'].apply(clean_text)\n",
    "X_2018_tfidf = tfidf.transform(df_18['text'])\n",
    "pred_2018 = model.predict(X_2018_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e66b0ba8-6f11-4db7-904a-7789f3bd8bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 2016: Counter({0: 302, 1: 122})\n",
      "Prediction 2018: Counter({0: 1872, 1: 1684})\n"
     ]
    }
   ],
   "source": [
    "c1 = Counter(pred_2018)\n",
    "\n",
    "print(\"Prediction 2016:\", c)\n",
    "print(\"Prediction 2018:\", c1)\n",
    "#class label 1  (Trump), 0  (not trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d946167a-337a-420f-98fa-3d1f7963194b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3556"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1872+1684"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27af86-f6a5-4df3-b326-d28b2c97faa0",
   "metadata": {},
   "source": [
    "#Data Insights\n",
    "Who writes the tweets that come from the other devices during 2016. How confident can we be in these results?\n",
    "As our SVM classfier give decent accuracy on both train and test set we can be confident on the prediction but we need moree datapoints to understand the patterns in which trump writes his tweets, with that our model can be improved\n",
    "\n",
    "● Run the classifier on tweets from Jan-Dec 2018. Do you think this classifier is still\n",
    "valid, or has something changed [e.g., perhaps Trump is no longer posting tweets]?\n",
    "How reliable is it for this year?\n",
    "our classfier predicts that out of 3556 Trump tweeted was fairly active and twetted around 1684 tweets., this may or may not be the case as external factors like sanction are not taking into consideration while training the model hence i think we need to train the model on newer data points + more factors like identify the way trump tweets etc to build a more robust model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a6a39-a588-48c7-b991-56f58bdfcad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
